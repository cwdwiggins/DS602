{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 10 - PCA and Dimension Reduction Homework\n",
    "Execute the below code and answer the following questions. __Do NOT commit the csv file!__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "def generate_data():\n",
    "    x, y = make_classification(n_samples=1500, \n",
    "                            n_features = 20,\n",
    "                            n_informative = 8,\n",
    "                            n_redundant = 5,\n",
    "                            n_repeated = 1, \n",
    "                            n_classes = 3,\n",
    "                            weights = (0.5, 0.25, 0.25),\n",
    "                            random_state = 120\n",
    "                            )\n",
    "    colNames = ['var'+str(x) for x in range(20)]\n",
    "    colNames.append('target')\n",
    "\n",
    "    df = pd.DataFrame(np.concatenate((x,y.reshape(-1,1)), axis=1), columns=colNames)\n",
    "#     df.to_csv('pca-dataset.csv', index=False)\n",
    "    return df\n",
    "    \n",
    "df = generate_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var0</th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>var3</th>\n",
       "      <th>var4</th>\n",
       "      <th>var5</th>\n",
       "      <th>var6</th>\n",
       "      <th>var7</th>\n",
       "      <th>var8</th>\n",
       "      <th>var9</th>\n",
       "      <th>...</th>\n",
       "      <th>var11</th>\n",
       "      <th>var12</th>\n",
       "      <th>var13</th>\n",
       "      <th>var14</th>\n",
       "      <th>var15</th>\n",
       "      <th>var16</th>\n",
       "      <th>var17</th>\n",
       "      <th>var18</th>\n",
       "      <th>var19</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.882513</td>\n",
       "      <td>-3.272465</td>\n",
       "      <td>-2.520732</td>\n",
       "      <td>-1.987174</td>\n",
       "      <td>-2.073689</td>\n",
       "      <td>-3.272465</td>\n",
       "      <td>-1.237969</td>\n",
       "      <td>1.690547</td>\n",
       "      <td>-0.211314</td>\n",
       "      <td>-5.753190</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.574979</td>\n",
       "      <td>-1.916275</td>\n",
       "      <td>-5.994075</td>\n",
       "      <td>-3.349615</td>\n",
       "      <td>-0.846193</td>\n",
       "      <td>2.491347</td>\n",
       "      <td>1.360958</td>\n",
       "      <td>-2.892522</td>\n",
       "      <td>-1.377561</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.775242</td>\n",
       "      <td>-1.015994</td>\n",
       "      <td>0.005137</td>\n",
       "      <td>0.057274</td>\n",
       "      <td>0.590205</td>\n",
       "      <td>-1.015994</td>\n",
       "      <td>1.350954</td>\n",
       "      <td>-1.493037</td>\n",
       "      <td>-0.862391</td>\n",
       "      <td>-1.986047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.523760</td>\n",
       "      <td>0.399579</td>\n",
       "      <td>0.088600</td>\n",
       "      <td>0.718606</td>\n",
       "      <td>-1.112030</td>\n",
       "      <td>0.083929</td>\n",
       "      <td>0.606544</td>\n",
       "      <td>-1.376793</td>\n",
       "      <td>1.302641</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.876376</td>\n",
       "      <td>0.220453</td>\n",
       "      <td>3.114224</td>\n",
       "      <td>-1.640025</td>\n",
       "      <td>1.180348</td>\n",
       "      <td>0.220453</td>\n",
       "      <td>0.465102</td>\n",
       "      <td>0.222511</td>\n",
       "      <td>0.880455</td>\n",
       "      <td>2.922315</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.370516</td>\n",
       "      <td>3.585262</td>\n",
       "      <td>-2.168162</td>\n",
       "      <td>2.693429</td>\n",
       "      <td>-0.966636</td>\n",
       "      <td>1.586302</td>\n",
       "      <td>-2.821546</td>\n",
       "      <td>0.482164</td>\n",
       "      <td>0.187404</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.550342</td>\n",
       "      <td>-1.968144</td>\n",
       "      <td>0.077681</td>\n",
       "      <td>-1.887719</td>\n",
       "      <td>1.864445</td>\n",
       "      <td>-1.968144</td>\n",
       "      <td>-0.527958</td>\n",
       "      <td>-0.201467</td>\n",
       "      <td>-0.532649</td>\n",
       "      <td>2.287445</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041341</td>\n",
       "      <td>2.383582</td>\n",
       "      <td>-0.417253</td>\n",
       "      <td>1.305379</td>\n",
       "      <td>-0.435123</td>\n",
       "      <td>-0.468557</td>\n",
       "      <td>0.923290</td>\n",
       "      <td>3.880050</td>\n",
       "      <td>2.676798</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.454974</td>\n",
       "      <td>1.293300</td>\n",
       "      <td>0.112201</td>\n",
       "      <td>-0.589989</td>\n",
       "      <td>-1.674321</td>\n",
       "      <td>1.293300</td>\n",
       "      <td>0.487302</td>\n",
       "      <td>1.776318</td>\n",
       "      <td>0.702520</td>\n",
       "      <td>-1.024127</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.452869</td>\n",
       "      <td>-0.667306</td>\n",
       "      <td>0.345364</td>\n",
       "      <td>-3.920591</td>\n",
       "      <td>-0.438296</td>\n",
       "      <td>-1.690141</td>\n",
       "      <td>0.176906</td>\n",
       "      <td>1.920142</td>\n",
       "      <td>1.474634</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       var0      var1      var2      var3      var4      var5      var6  \\\n",
       "0 -2.882513 -3.272465 -2.520732 -1.987174 -2.073689 -3.272465 -1.237969   \n",
       "1  0.775242 -1.015994  0.005137  0.057274  0.590205 -1.015994  1.350954   \n",
       "2 -0.876376  0.220453  3.114224 -1.640025  1.180348  0.220453  0.465102   \n",
       "3 -2.550342 -1.968144  0.077681 -1.887719  1.864445 -1.968144 -0.527958   \n",
       "4 -0.454974  1.293300  0.112201 -0.589989 -1.674321  1.293300  0.487302   \n",
       "\n",
       "       var7      var8      var9  ...     var11     var12     var13     var14  \\\n",
       "0  1.690547 -0.211314 -5.753190  ... -0.574979 -1.916275 -5.994075 -3.349615   \n",
       "1 -1.493037 -0.862391 -1.986047  ...  0.523760  0.399579  0.088600  0.718606   \n",
       "2  0.222511  0.880455  2.922315  ... -0.370516  3.585262 -2.168162  2.693429   \n",
       "3 -0.201467 -0.532649  2.287445  ... -0.041341  2.383582 -0.417253  1.305379   \n",
       "4  1.776318  0.702520 -1.024127  ... -0.452869 -0.667306  0.345364 -3.920591   \n",
       "\n",
       "      var15     var16     var17     var18     var19  target  \n",
       "0 -0.846193  2.491347  1.360958 -2.892522 -1.377561     0.0  \n",
       "1 -1.112030  0.083929  0.606544 -1.376793  1.302641     2.0  \n",
       "2 -0.966636  1.586302 -2.821546  0.482164  0.187404     0.0  \n",
       "3 -0.435123 -0.468557  0.923290  3.880050  2.676798     1.0  \n",
       "4 -0.438296 -1.690141  0.176906  1.920142  1.474634     0.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1500 entries, 0 to 1499\n",
      "Data columns (total 21 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   var0    1500 non-null   float64\n",
      " 1   var1    1500 non-null   float64\n",
      " 2   var2    1500 non-null   float64\n",
      " 3   var3    1500 non-null   float64\n",
      " 4   var4    1500 non-null   float64\n",
      " 5   var5    1500 non-null   float64\n",
      " 6   var6    1500 non-null   float64\n",
      " 7   var7    1500 non-null   float64\n",
      " 8   var8    1500 non-null   float64\n",
      " 9   var9    1500 non-null   float64\n",
      " 10  var10   1500 non-null   float64\n",
      " 11  var11   1500 non-null   float64\n",
      " 12  var12   1500 non-null   float64\n",
      " 13  var13   1500 non-null   float64\n",
      " 14  var14   1500 non-null   float64\n",
      " 15  var15   1500 non-null   float64\n",
      " 16  var16   1500 non-null   float64\n",
      " 17  var17   1500 non-null   float64\n",
      " 18  var18   1500 non-null   float64\n",
      " 19  var19   1500 non-null   float64\n",
      " 20  target  1500 non-null   float64\n",
      "dtypes: float64(21)\n",
      "memory usage: 246.2 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 1,200\n",
      "Test samples: 300\n",
      "\n",
      "Features:\n",
      "var0\tvar1\tvar2\tvar3\tvar4\tvar5\tvar6\tvar7\tvar8\tvar9\tvar10\tvar11\tvar12\tvar13\tvar14\tvar15\tvar16\tvar17\tvar18\tvar19\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[[x for x in df.columns if x.startswith('var')]]\n",
    "y = df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "print(f'Training samples: {X_train.shape[0]:,}')\n",
    "print(f'Test samples: {X_test.shape[0]:,}')\n",
    "\n",
    "print('\\nFeatures:')\n",
    "print(*X_train, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Description\n",
    "- `var1 - var19`: a feature for the data.  \n",
    "- `target`: variable we wish to be able to predict, which is 1 of 3 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "- Use principle components analysis to determine the number of components to reduce the data to by evaluating the explained variance ratio (use `X_train`).  \n",
    "- Remember to scale the data first.  \n",
    "- What number of components would you recommend based on your analysis?  \n",
    "- Explain your results using markdown cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert code here\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "X_test_std = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "cov_mat = np.cov(X_train_std.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigen_vals, eigen_vecs = np.linalg.eig(cov_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\lib\\site-packages\\matplotlib\\cbook.py:1699: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return math.isfinite(val)\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\matplotlib\\transforms.py:766: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  points = np.asarray(points, float)\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\matplotlib\\cbook.py:1345: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return np.asarray(x, float)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tot = sum(eigen_vals)\n",
    "\n",
    "var_exp = [(i / tot) for i in sorted(eigen_vals, reverse=True)]\n",
    "cum_var_exp = np.cumsum(var_exp)\n",
    "\n",
    "plt.bar(range(1,21), var_exp, alpha=0.5, align='center', label='Variance Explained')\n",
    "plt.step(range(1,21), cum_var_exp, where='mid', label='Cumulative Explained')\n",
    "plt.xlabel('Principal Componment')\n",
    "plt.ylabel('Explained Variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Since there's no principal component that explains a large portion of the variance in data, we will have to use a higher number of principal components. According to the graph, about 80% of the data is explained with 10 principal components, so it would be best use 10 principal components in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Insert comments>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "- Evaluate the target variable in the `df` object.  \n",
    "- Which metric would you use in evaluating a predictive model. Explain your choice in the markdown cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert code here\n",
    "target_groups = df.groupby(['target']).target.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.barh(target_groups.index, target_groups, height=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The results here show that the dataset is inbalance in favor of class zero. This means that accuracy would not be a good evaluation metric. Here, we could use a weighted F1-score instead to evaluate the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "- Without using PCA, create a logistic regression model using practices discussed in class.  \n",
    "- Which model would you choose? Explain your results in the markdown cells.    \n",
    "- What is the accuracy, precision, and recall for the test data?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaling&#x27;, StandardScaler()),\n",
       "                (&#x27;model&#x27;, LogisticRegression(C=10))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaling&#x27;, StandardScaler()),\n",
       "                (&#x27;model&#x27;, LogisticRegression(C=10))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=10)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaling', StandardScaler()),\n",
       "                ('model', LogisticRegression(C=10))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert code here\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "p = Pipeline([\n",
    "    ('scaling', StandardScaler()),\n",
    "    ('model', LogisticRegression())\n",
    "])\n",
    "\n",
    "params = {'model__C': [0.01, 0.1, 1, 10]}\n",
    "\n",
    "lr_cv = GridSearchCV(p, param_grid=params, scoring='f1_weighted', cv=5, refit=True)\n",
    "lr_cv = lr_cv.fit(X_train, y_train)\n",
    "\n",
    "lr_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 71.88%\n",
      "Test score: 70.27%\n"
     ]
    }
   ],
   "source": [
    "print(f'Validation score: {lr_cv.best_score_:.2%}')\n",
    "print(f'Test score: {lr_cv.score(X_test, y_test):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = lr_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.76      0.76       153\n",
      "         1.0       0.68      0.59      0.63        74\n",
      "         2.0       0.62      0.68      0.65        73\n",
      "\n",
      "    accuracy                           0.70       300\n",
      "   macro avg       0.69      0.68      0.68       300\n",
      "weighted avg       0.70      0.70      0.70       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> For the test data, the accuracy is 70%. The precision came back as 75% for class 0, 68% for class 1, and 62% for class 2. The recall was 76% for class 0, 59% for class 1, and 68% for class 2. For this model, using GridSearch, we chose a logistic regression model with a C hyperparameter equal to 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "- Use PCA within a pipeline to create a logistic regression model using best practices from class.  \n",
    "- Which model performs the best on the training data? Explain your results in markdown cells.  \n",
    "- What is the accuracy, precision, and recall for the test data?\n",
    "- Does this perform better than the original logistic regression model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaling&#x27;, StandardScaler()), (&#x27;pca&#x27;, PCA(n_components=11)),\n",
       "                (&#x27;model&#x27;, LogisticRegression(C=0.1))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaling&#x27;, StandardScaler()), (&#x27;pca&#x27;, PCA(n_components=11)),\n",
       "                (&#x27;model&#x27;, LogisticRegression(C=0.1))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=11)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.1)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaling', StandardScaler()), ('pca', PCA(n_components=11)),\n",
       "                ('model', LogisticRegression(C=0.1))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert code\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "p = Pipeline([\n",
    "    ('scaling', StandardScaler()),\n",
    "    ('pca', PCA()),\n",
    "    ('model', LogisticRegression())\n",
    "])\n",
    "\n",
    "params = {'model__C': [0.01, 0.1, 1, 10], 'pca__n_components': [5, 6, 7, 8, 9, 10, 11, 12]}\n",
    "\n",
    "lr_pca_cv = GridSearchCV(p, param_grid=params, scoring='f1_weighted', cv=5, refit=True)\n",
    "lr_pca_cv = lr_pca_cv.fit(X_train, y_train)\n",
    "\n",
    "lr_pca_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 70.69%\n",
      "Test score: 69.78%\n"
     ]
    }
   ],
   "source": [
    "print(f'Validation score: {lr_pca_cv.best_score_:.2%}')\n",
    "print(f'Test score: {lr_pca_cv.score(X_test, y_test):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.78      0.76       153\n",
      "         1.0       0.64      0.55      0.59        74\n",
      "         2.0       0.65      0.68      0.67        73\n",
      "\n",
      "    accuracy                           0.70       300\n",
      "   macro avg       0.68      0.67      0.67       300\n",
      "weighted avg       0.70      0.70      0.70       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_hat = lr_pca_cv.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> For this model, the accuracy was 70%. The precision for was 75% for class 0, 64% for class 1, and 65% for class 2. The recall was 78% for class 0, 55% for class 1, and 68% for class 2. The weighted average for the f1 score was 70%. Comparing the metrics from both models, there is not much difference. After using GridSearch, the hyperparameters selected for this model were 11 prinicpal components (k) and 0.1 for C."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Without using PCA, create a decision tree model using best practices discussed in class.  \n",
    "- Which model performs the best on the training data? Explain your results in the markdown cells.  \n",
    "- What is the accuracy, precision, and recall for the test data?  \n",
    "- Does this perform better than either of the logistic regression models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaling&#x27;, StandardScaler()),\n",
       "                (&#x27;model&#x27;, DecisionTreeClassifier(max_depth=10))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaling&#x27;, StandardScaler()),\n",
       "                (&#x27;model&#x27;, DecisionTreeClassifier(max_depth=10))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=10)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaling', StandardScaler()),\n",
       "                ('model', DecisionTreeClassifier(max_depth=10))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert code here\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "p = Pipeline([\n",
    "    ('scaling', StandardScaler()),\n",
    "    ('model', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "params = {'model__max_depth': [1, 5, 10, 15, 20]}\n",
    "\n",
    "dt_cv = GridSearchCV(p, param_grid=params, scoring='f1_weighted', cv=5, refit=True)\n",
    "dt_cv = dt_cv.fit(X_train, y_train)\n",
    "\n",
    "dt_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 75.45%\n",
      "Test score: 69.54%\n"
     ]
    }
   ],
   "source": [
    "print(f'Validation score: {dt_cv.best_score_:.2%}')\n",
    "print(f'Test score: {dt_cv.score(X_test, y_test):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.78      0.77       153\n",
      "         1.0       0.59      0.64      0.61        74\n",
      "         2.0       0.69      0.58      0.63        73\n",
      "\n",
      "    accuracy                           0.70       300\n",
      "   macro avg       0.68      0.66      0.67       300\n",
      "weighted avg       0.70      0.70      0.70       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_hat = dt_cv.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The weighted F1 test score for this model was 69.54%, and for the other logistic regression models, each had a weighted F1 test score of 70.27% (without PCA) and 69.78% (with PCA). Thus, this model did not perform better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6\n",
    "- Repeat `Question 5` but use PCA.  \n",
    "- Does this perform better than the original Decision Tree or the logistic regression models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaling&#x27;, StandardScaler()), (&#x27;pca&#x27;, PCA(n_components=6)),\n",
       "                (&#x27;model&#x27;, DecisionTreeClassifier(max_depth=10))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaling&#x27;, StandardScaler()), (&#x27;pca&#x27;, PCA(n_components=6)),\n",
       "                (&#x27;model&#x27;, DecisionTreeClassifier(max_depth=10))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=6)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=10)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaling', StandardScaler()), ('pca', PCA(n_components=6)),\n",
       "                ('model', DecisionTreeClassifier(max_depth=10))])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert code here\n",
    "\n",
    "p = Pipeline([\n",
    "    ('scaling', StandardScaler()),\n",
    "    ('pca', PCA()),\n",
    "    ('model', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "params = {'model__max_depth': [1, 5, 10, 15, 20], 'pca__n_components': [5, 6, 7, 8, 9, 10, 11, 12]}\n",
    "\n",
    "dt_pca_cv = GridSearchCV(p, param_grid=params, scoring='f1_weighted', cv=5, refit=True)\n",
    "dt_pca_cv = dt_pca_cv.fit(X_train, y_train)\n",
    "\n",
    "dt_pca_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 69.43%\n",
      "Test score: 69.84%\n"
     ]
    }
   ],
   "source": [
    "print(f'Validation score: {dt_pca_cv.best_score_:.2%}')\n",
    "print(f'Test score: {dt_pca_cv.score(X_test, y_test):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.78      0.77       153\n",
      "         1.0       0.67      0.59      0.63        74\n",
      "         2.0       0.62      0.63      0.63        73\n",
      "\n",
      "    accuracy                           0.70       300\n",
      "   macro avg       0.68      0.67      0.67       300\n",
      "weighted avg       0.70      0.70      0.70       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_hat = dt_pca_cv.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The weighted F1 test score here returned as 69.84%. From this model, the precision was 75% for class 0, 67% for class 1, and 62% for class 2. The recall was 78% for class 0, 59% for class 1, and 63% for class 2. The F1 score was 77% for class 0, 63% for class 1, and 63% for class 2. These scores are not much different to the same scores from the Logistic Regression and Decision Tree (without PCA) models. Thus, this model did not perform any better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
